{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c8a9771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0bff4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEP_A</th>\n",
       "      <th>SEX_A</th>\n",
       "      <th>HISPALLP_A</th>\n",
       "      <th>EDUCP_A</th>\n",
       "      <th>BMICAT_A</th>\n",
       "      <th>SMKCIGST_A</th>\n",
       "      <th>HYPEV_A</th>\n",
       "      <th>CHLEV_A</th>\n",
       "      <th>DIBEV_A</th>\n",
       "      <th>PHSTAT_A</th>\n",
       "      <th>DEPEV_A</th>\n",
       "      <th>COPDEV_A</th>\n",
       "      <th>STREV_A</th>\n",
       "      <th>CHDEV_A</th>\n",
       "      <th>ANGEV_A</th>\n",
       "      <th>MIEV_A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29517</th>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29518</th>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29519</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29520</th>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29521</th>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29522 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AGEP_A  SEX_A  HISPALLP_A  EDUCP_A  BMICAT_A  SMKCIGST_A  HYPEV_A  \\\n",
       "0          67      1           3        1         3           4        1   \n",
       "1          73      1           2        8         3           1        1   \n",
       "2          48      1           3        5         4           4        2   \n",
       "3          42      2           2        9         3           3        2   \n",
       "4          50      2           2        7         2           4        2   \n",
       "...       ...    ...         ...      ...       ...         ...      ...   \n",
       "29517      77      2           2        5         4           3        1   \n",
       "29518      59      2           2        7         3           4        2   \n",
       "29519      66      1           2        8         4           4        2   \n",
       "29520      53      2           2        7         3           1        1   \n",
       "29521      72      2           2        8         2           3        1   \n",
       "\n",
       "       CHLEV_A  DIBEV_A  PHSTAT_A  DEPEV_A  COPDEV_A  STREV_A  CHDEV_A  \\\n",
       "0            1        2         5        1         2        1        2   \n",
       "1            2        1         3        2         2        2        1   \n",
       "2            2        2         1        2         2        2        2   \n",
       "3            2        2         1        2         2        2        2   \n",
       "4            2        2         2        2         2        2        2   \n",
       "...        ...      ...       ...      ...       ...      ...      ...   \n",
       "29517        1        2         3        1         1        2        2   \n",
       "29518        1        2         1        1         2        2        2   \n",
       "29519        2        2         3        2         2        2        2   \n",
       "29520        2        2         2        2         2        2        2   \n",
       "29521        1        2         3        2         2        2        2   \n",
       "\n",
       "       ANGEV_A  MIEV_A  \n",
       "0            2       2  \n",
       "1            2       1  \n",
       "2            2       2  \n",
       "3            2       2  \n",
       "4            2       2  \n",
       "...        ...     ...  \n",
       "29517        2       2  \n",
       "29518        2       2  \n",
       "29519        2       2  \n",
       "29520        2       2  \n",
       "29521        2       2  \n",
       "\n",
       "[29522 rows x 16 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemini_features = [\n",
    "    \"AGEP_A\",          # age (years, 18â€‘85 topâ€‘coded)\n",
    "    \"SEX_A\",           # sex\n",
    "    \"HISPALLP_A\",      # combined race / ethnicity\n",
    "    \"EDUCP_A\",         # education level\n",
    "    \"BMICAT_A\",        # BMI category\n",
    "    \"SMKCIGST_A\",      # smoking status\n",
    "    \"HYPEV_A\",         # ever hypertension\n",
    "    \"CHLEV_A\",         # ever high cholesterol\n",
    "    \"DIBEV_A\",         # ever diabetes\n",
    "    \"PHSTAT_A\",        # selfâ€‘rated health\n",
    "    \"DEPEV_A\",         # ever depression\n",
    "    \"COPDEV_A\",        # ever COPD / chronic bronchitis / emphysema\n",
    "    \"STREV_A\"          # ever stroke\n",
    "]\n",
    "\n",
    "target_columns = ['CHDEV_A', 'ANGEV_A', 'MIEV_A']\n",
    "\n",
    "data_df = pd.read_csv('adult23.csv')\n",
    "data_df = data_df[gemini_features + target_columns]\n",
    "\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "747bd495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_codes(col, mapping, unknown=\"Unknown\"):\n",
    "    \"\"\"Map numeric codes to text; keep <NA>; anything else â†’ 'Unknown'.\"\"\"\n",
    "    return (\n",
    "        col.replace(mapping)          # map known codes\n",
    "           .mask(col.isna(), pd.NA)   # preserve genuine <NA>\n",
    "           .fillna(unknown)           # leftover unusual codes\n",
    "           .astype(\"string\")\n",
    "    )\n",
    "\n",
    "data_df[\"SEX_A\"] = map_codes(data_df[\"SEX_A\"], {1: \"Male\",  2: \"Female\"})\n",
    "\n",
    "data_df[\"HISPALLP_A\"] = map_codes(data_df[\"HISPALLP_A\"],{\n",
    "    1: \"Hispanic\", 2: \"Whiteâ€‘NH\", 3: \"Blackâ€‘NH\", 4: \"Asianâ€‘NH\",\n",
    "    5: \"AIANâ€‘NH\",  6: \"AIAN+Other\", 7: \"Other\"})\n",
    "\n",
    "data_df[\"EDUCP_A\"] = map_codes(data_df[\"EDUCP_A\"], {\n",
    "    0: \"None/KG\", 1: \"1â€“11th\", 2: \"12th/no dip\", 3: \"GED\",\n",
    "    4: \"HS Grad\", 5: \"Some College\", 6: \"Assocâ€‘Occ/Voc\",\n",
    "    7: \"Assocâ€‘Acad\", 8: \"Bachelor\", 9: \"Master\", 10: \"Prof/PhD\"})\n",
    "\n",
    "data_df[\"BMICAT_A\"] = map_codes(data_df[\"BMICAT_A\"], {\n",
    "    1: \"Under\", 2: \"Normal\", 3: \"Over\", 4: \"Obese\", 5: \"ExtObese\"})\n",
    "\n",
    "data_df[\"SMKCIGST_A\"] = map_codes(data_df[\"SMKCIGST_A\"], {\n",
    "    1: \"Every day\", 2: \"Some days\", 3: \"Former\", 4: \"Never\"})\n",
    "\n",
    "data_df[\"PHSTAT_A\"] = map_codes(data_df[\"PHSTAT_A\"], {\n",
    "    1: \"Excellent\", 2: \"Very good\", 3: \"Good\", 4: \"Fair\", 5: \"Poor\"})\n",
    "\n",
    "binary_variables = [\"HYPEV_A\", \"CHLEV_A\", \"DIBEV_A\", \"DEPEV_A\", \"COPDEV_A\", \"STREV_A\"]\n",
    "\n",
    "for col in binary_variables:\n",
    "    data_df[col] = map_codes(data_df[col], {1: \"Yes\", 2: \"No\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "744417de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df[\"heart_disease\"] = (\n",
    "    (data_df[\"CHDEV_A\"] == 1) | \n",
    "    (data_df[\"ANGEV_A\"] == 1) | \n",
    "    (data_df[\"MIEV_A\"] == 1)\n",
    ").astype(int)\n",
    "\n",
    "X = data_df.drop(columns=[\"heart_disease\"] + target_columns)\n",
    "y = data_df[\"heart_disease\"]\n",
    "\n",
    "# Defining the categorical and numerical columns (just age in this case)\n",
    "cat_cols = X.columns.tolist()           \n",
    "cat_cols.remove(\"AGEP_A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d8eb0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(\n",
    "        sparse_output=False,\n",
    "        handle_unknown=\"ignore\"\n",
    "      )\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "        [(\"onehot\", ohe, cat_cols)],\n",
    "        remainder=\"passthrough\"\n",
    "     )\n",
    "\n",
    "X_encoded = ct.fit_transform(X)\n",
    "\n",
    "feature_names = (\n",
    "    ct.named_transformers_[\"onehot\"]\n",
    "      .get_feature_names_out(cat_cols)\n",
    "      .tolist() + [\"AGEP_A\"]\n",
    ")\n",
    "X_final = pd.DataFrame(X_encoded, columns=feature_names, index=X.index)\n",
    "\n",
    "# sanity check â€“ no NA left\n",
    "assert X_final.isna().sum().sum() == 0, \"still missing values!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ace31dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END clf__C=0.01, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear; total time=   0.1s\n",
      "[CV] END clf__C=0.01, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear; total time=   0.1s\n",
      "[CV] END clf__C=0.01, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear; total time=   0.1s\n",
      "[CV] END clf__C=0.01, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear; total time=   0.1s\n",
      "[CV] END clf__C=0.01, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear; total time=   0.1s\n",
      "[CV] END clf__C=0.01, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs; total time=   0.1s\n",
      "[CV] END clf__C=0.01, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs; total time=   0.2s\n",
      "[CV] END clf__C=0.01, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs; total time=   0.2s\n",
      "[CV] END clf__C=0.01, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs; total time=   0.1s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear; total time=   0.1s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear; total time=   0.1s\n",
      "[CV] END clf__C=0.01, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs; total time=   0.2s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear; total time=   0.1s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear; total time=   0.0s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear; total time=   0.1s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs; total time=   0.1s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs; total time=   0.1s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs; total time=   0.1s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs; total time=   0.1s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs; total time=   0.1s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear; total time=   0.1s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear; total time=   0.1s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear; total time=   0.1s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear; total time=   0.1s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs; total time=   0.1s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear; total time=   0.1s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs; total time=   0.1s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs; total time=   0.1s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs; total time=   0.1s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs; total time=   0.1s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear; total time=   0.1s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear; total time=   0.1s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear; total time=   0.1s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear; total time=   0.1s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs; total time=   0.1s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs; total time=   0.1s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs; total time=   0.1s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear; total time=   0.1s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs; total time=   0.1s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs; total time=   0.1s\n",
      "[CV] END clf__C=100, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear; total time=   0.1s\n",
      "[CV] END clf__C=100, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear; total time=   0.1s\n",
      "[CV] END clf__C=100, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear; total time=   0.1s\n",
      "[CV] END clf__C=100, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear; total time=   0.1s\n",
      "[CV] END clf__C=100, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs; total time=   0.1s\n",
      "[CV] END clf__C=100, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs; total time=   0.1s\n",
      "[CV] END clf__C=100, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs; total time=   0.1s\n",
      "[CV] END clf__C=100, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs; total time=   0.1s\n",
      "[CV] END clf__C=100, clf__class_weight=balanced, clf__penalty=l2, clf__solver=liblinear; total time=   0.1s\n",
      "[CV] END clf__C=100, clf__class_weight=balanced, clf__penalty=l2, clf__solver=lbfgs; total time=   0.1s\n",
      "Best LR parameters: {'clf__C': 0.01, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_final, y, test_size=0.20, stratify=y, random_state=42\n",
    ")\n",
    "pipe_lr = Pipeline([\n",
    "    (\"scale\", StandardScaler(with_mean=False)),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000, class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "param_grid_lr = {\n",
    "    'clf__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'clf__penalty': ['l2'],\n",
    "    'clf__solver': ['liblinear', 'lbfgs'],\n",
    "    'clf__class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "grid_lr = GridSearchCV(pipe_lr, param_grid_lr, scoring='f1', cv=5, n_jobs=-1, verbose=2)\n",
    "grid_lr.fit(X_train, y_train)\n",
    "best_lr = grid_lr.best_estimator_\n",
    "print(\"Best LR parameters:\", grid_lr.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "658bb988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END class_weight=balanced, max_depth=None, min_samples_split=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END class_weight=balanced, max_depth=None, min_samples_split=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END class_weight=balanced, max_depth=None, min_samples_split=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END class_weight=balanced, max_depth=None, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END class_weight=balanced, max_depth=None, min_samples_split=2, n_estimators=100; total time=   1.6s\n",
      "[CV] END class_weight=balanced, max_depth=None, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END class_weight=balanced, max_depth=None, min_samples_split=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END class_weight=balanced, max_depth=None, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END class_weight=balanced, max_depth=None, min_samples_split=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END class_weight=balanced, max_depth=None, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END class_weight=balanced, max_depth=None, min_samples_split=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END class_weight=balanced, max_depth=None, min_samples_split=2, n_estimators=200; total time=   2.6s\n",
      "[CV] END class_weight=balanced, max_depth=None, min_samples_split=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END class_weight=balanced, max_depth=None, min_samples_split=2, n_estimators=200; total time=   2.7s\n",
      "[CV] END class_weight=balanced, max_depth=None, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END class_weight=balanced, max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END class_weight=balanced, max_depth=10, min_samples_split=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END class_weight=balanced, max_depth=10, min_samples_split=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END class_weight=balanced, max_depth=10, min_samples_split=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END class_weight=balanced, max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END class_weight=balanced, max_depth=None, min_samples_split=10, n_estimators=200; total time=   2.2s\n",
      "[CV] END class_weight=balanced, max_depth=None, min_samples_split=10, n_estimators=200; total time=   2.1s\n",
      "[CV] END class_weight=balanced, max_depth=None, min_samples_split=10, n_estimators=200; total time=   2.1s\n",
      "[CV] END class_weight=balanced, max_depth=None, min_samples_split=10, n_estimators=200; total time=   2.3s\n",
      "[CV] END class_weight=balanced, max_depth=None, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END class_weight=balanced, max_depth=10, min_samples_split=2, n_estimators=200; total time=   1.6s\n",
      "[CV] END class_weight=balanced, max_depth=10, min_samples_split=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END class_weight=balanced, max_depth=10, min_samples_split=2, n_estimators=200; total time=   1.8s\n",
      "[CV] END class_weight=balanced, max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.9s\n",
      "[CV] END class_weight=balanced, max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.9s\n",
      "[CV] END class_weight=balanced, max_depth=10, min_samples_split=2, n_estimators=200; total time=   1.8s\n",
      "[CV] END class_weight=balanced, max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END class_weight=balanced, max_depth=10, min_samples_split=2, n_estimators=200; total time=   1.7s\n",
      "[CV] END class_weight=balanced, max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.8s\n",
      "[CV] END class_weight=balanced, max_depth=10, min_samples_split=2, n_estimators=200; total time=   1.9s\n",
      "[CV] END class_weight=balanced, max_depth=20, min_samples_split=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END class_weight=balanced, max_depth=20, min_samples_split=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END class_weight=balanced, max_depth=20, min_samples_split=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END class_weight=balanced, max_depth=20, min_samples_split=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END class_weight=balanced, max_depth=20, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END class_weight=balanced, max_depth=10, min_samples_split=10, n_estimators=200; total time=   1.6s\n",
      "[CV] END class_weight=balanced, max_depth=10, min_samples_split=10, n_estimators=200; total time=   1.8s\n",
      "[CV] END class_weight=balanced, max_depth=10, min_samples_split=10, n_estimators=200; total time=   1.7s\n",
      "[CV] END class_weight=balanced, max_depth=10, min_samples_split=10, n_estimators=200; total time=   1.7s\n",
      "[CV] END class_weight=balanced, max_depth=10, min_samples_split=10, n_estimators=200; total time=   1.8s\n",
      "[CV] END class_weight=balanced, max_depth=20, min_samples_split=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END class_weight=balanced, max_depth=20, min_samples_split=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END class_weight=balanced, max_depth=20, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END class_weight=balanced, max_depth=20, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END class_weight=balanced, max_depth=20, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END class_weight=balanced, max_depth=20, min_samples_split=2, n_estimators=200; total time=   2.2s\n",
      "[CV] END class_weight=balanced, max_depth=20, min_samples_split=2, n_estimators=200; total time=   2.0s\n",
      "[CV] END class_weight=balanced, max_depth=20, min_samples_split=2, n_estimators=200; total time=   2.3s\n",
      "[CV] END class_weight=balanced, max_depth=20, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END class_weight=balanced, max_depth=20, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END class_weight=balanced, max_depth=20, min_samples_split=10, n_estimators=200; total time=   1.6s\n",
      "[CV] END class_weight=balanced, max_depth=20, min_samples_split=10, n_estimators=200; total time=   1.5s\n",
      "[CV] END class_weight=balanced, max_depth=20, min_samples_split=10, n_estimators=200; total time=   1.4s\n",
      "[CV] END class_weight=balanced, max_depth=20, min_samples_split=10, n_estimators=200; total time=   1.4s\n",
      "[CV] END class_weight=balanced, max_depth=20, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "Best RF parameters: {'class_weight': 'balanced', 'max_depth': None, 'min_samples_split': 10, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 10],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    param_grid_rf,\n",
    "    scoring='f1',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "grid_rf.fit(X_train, y_train)\n",
    "best_rf = grid_rf.best_estimator_\n",
    "print(\"Best RF parameters:\", grid_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdb18d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, scale_pos_weight=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, scale_pos_weight=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, scale_pos_weight=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, scale_pos_weight=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, scale_pos_weight=11.23045054375971; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, scale_pos_weight=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, scale_pos_weight=11.23045054375971; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, scale_pos_weight=11.23045054375971; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, scale_pos_weight=11.23045054375971; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, scale_pos_weight=11.23045054375971; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, scale_pos_weight=11.23045054375971; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, scale_pos_weight=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, scale_pos_weight=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, scale_pos_weight=11.23045054375971; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, scale_pos_weight=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, scale_pos_weight=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, scale_pos_weight=11.23045054375971; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, scale_pos_weight=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, scale_pos_weight=11.23045054375971; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, scale_pos_weight=11.23045054375971; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, scale_pos_weight=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, scale_pos_weight=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, scale_pos_weight=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, scale_pos_weight=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, scale_pos_weight=11.23045054375971; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, scale_pos_weight=11.23045054375971; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, scale_pos_weight=11.23045054375971; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, scale_pos_weight=11.23045054375971; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, scale_pos_weight=11.23045054375971; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, scale_pos_weight=1; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, scale_pos_weight=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, scale_pos_weight=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, scale_pos_weight=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, scale_pos_weight=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, scale_pos_weight=11.23045054375971; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, scale_pos_weight=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, scale_pos_weight=11.23045054375971; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, scale_pos_weight=11.23045054375971; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, scale_pos_weight=11.23045054375971; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, scale_pos_weight=11.23045054375971; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, scale_pos_weight=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, scale_pos_weight=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, scale_pos_weight=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, scale_pos_weight=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, scale_pos_weight=11.23045054375971; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, scale_pos_weight=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, scale_pos_weight=11.23045054375971; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, scale_pos_weight=11.23045054375971; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, scale_pos_weight=11.23045054375971; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, scale_pos_weight=11.23045054375971; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, scale_pos_weight=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, scale_pos_weight=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, scale_pos_weight=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, scale_pos_weight=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, scale_pos_weight=11.23045054375971; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, scale_pos_weight=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, scale_pos_weight=11.23045054375971; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, scale_pos_weight=11.23045054375971; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, scale_pos_weight=11.23045054375971; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, scale_pos_weight=11.23045054375971; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, scale_pos_weight=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, scale_pos_weight=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, scale_pos_weight=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, scale_pos_weight=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, scale_pos_weight=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, scale_pos_weight=11.23045054375971; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, scale_pos_weight=11.23045054375971; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, scale_pos_weight=11.23045054375971; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, scale_pos_weight=11.23045054375971; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, scale_pos_weight=11.23045054375971; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, scale_pos_weight=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, scale_pos_weight=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, scale_pos_weight=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, scale_pos_weight=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, scale_pos_weight=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, scale_pos_weight=11.23045054375971; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, scale_pos_weight=11.23045054375971; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, scale_pos_weight=11.23045054375971; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, scale_pos_weight=11.23045054375971; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, scale_pos_weight=11.23045054375971; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:53:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'scale_pos_weight': 11.23045054375971}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5],\n",
    "    'learning_rate': [0.1, 0.01],\n",
    "    'scale_pos_weight': [1, (len(y_train) - sum(y_train)) / sum(y_train)]\n",
    "}\n",
    "\n",
    "grid_xgb = GridSearchCV(\n",
    "    estimator=XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_xgb.fit(X_train, y_train)\n",
    "best_xgb_model = grid_xgb.best_estimator_\n",
    "print(\"Best XGBoost Params:\", grid_xgb.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a73fd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance on the test set:\n",
      "\n",
      "Logistic Regression - F1 Score: 0.346\n",
      "\n",
      "Random Forest - F1 Score: 0.373\n",
      "\n",
      "XGB Model - F1 Score: 0.351\n"
     ]
    }
   ],
   "source": [
    "best_models = [\n",
    "    (\"Logistic Regression\", best_lr),\n",
    "    (\"Random Forest\", best_rf),\n",
    "    (\"XGB Model\", best_xgb_model)\n",
    "]\n",
    "\n",
    "print(\"\\nPerformance on the test set:\")\n",
    "for name, model in best_models:\n",
    "    preds = model.predict(X_test)\n",
    "    print(f\"\\n{name} - F1 Score: {f1_score(y_test, preds):.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
